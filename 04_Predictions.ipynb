{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mneedham/data-science-training/blob/master/04_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "In this notebook we're going to learn how to build a link prediction classifier using Neo4j and scikit-learn. Let's start by importing the libraries that we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Update the cell below with the same Sandbox credentials that you used in the first notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the line of code below to use the IP Address, Bolt Port, and Password of your Sandbox.\n",
    "# graph = Graph(\"bolt://<IP Address>:<Bolt Port>\", auth=(\"neo4j\", \"<Password>\")) \n",
    "\n",
    "# graph = Graph(\"bolt://18.234.168.45:33679\", auth=(\"neo4j\", \"daybreak-cosal-rumbles\")) \n",
    "graph = Graph(\"bolt://localhost\", auth=(\"neo4j\", \"neo\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a co-author graph\n",
    "\n",
    "We're going to build an inferred graph of co-authors based on people collaborating on the same papers. We're also going to store a property on the relationship indicating the year of their first collaboration.\n",
    "\n",
    "We can run the query below to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constraints_added: 0\n",
       "constraints_removed: 0\n",
       "contains_updates: True\n",
       "indexes_added: 0\n",
       "indexes_removed: 0\n",
       "labels_added: 0\n",
       "labels_removed: 0\n",
       "nodes_created: 0\n",
       "nodes_deleted: 0\n",
       "properties_set: 465672\n",
       "relationships_created: 155224\n",
       "relationships_deleted: 0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "MATCH (a1)<-[:AUTHOR]-(paper)-[:AUTHOR]->(a2:Author)\n",
    "WITH a1, a2, paper\n",
    "ORDER BY a1, paper.year\n",
    "WITH a1, a2, collect(paper)[0].year AS year, count(*) AS collaborations\n",
    "MERGE (a1)-[coauthor:CO_AUTHOR {year: year}]-(a2)\n",
    "SET coauthor.collaborations = collaborations;\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query).stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created our co-author graph, we want to come up with an approach that will allow us to predict future links (relationships) that will be created between people. \n",
    "\n",
    "We're going to use the [link prediction algorithms](https://neo4j.com/docs/graph-algorithms/current/algorithms/linkprediction/) that we learnt about in the previous section, but once we've computed scores with this algorithms what should we do?\n",
    "\n",
    "There are two main approaches that we can take:\n",
    "\n",
    "### Using the measures directly\n",
    "\n",
    "We can use the scores from the link predictions directly, specifying a __threshold value__ above which we predict that a link will be created between two nodes.\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "We can take a supervised learning approach where we use the scores as features to train a binary classifier. The binary classifier then predicts whether a pair of nodes will have a link.\n",
    "\n",
    "In this notebook we're going to learn how to apply the supervised learning approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test datasets \n",
    "\n",
    "Now that we've decided we're going to use a machine learning approach, we need to come up with train and test datasets on which we can build, and then evaluate a model.\n",
    "\n",
    "### Positive examples\n",
    "\n",
    "The tricky thing when working with graph data is that we can't just randomly split the data, as this could lead to data leakage.\n",
    "\n",
    "Data leakage can occur when data outside of your training data is inadvertently used to create your model. This can easily happen when working with graphs because pairs of nodes in our training set may be connected to those in the test set.\n",
    "\n",
    "When we compute link prediction measures over that training set the __measures computed contain information from the test set__ that we’ll later evaluate our model against.\n",
    "\n",
    "Instead we need to split our graph into training and test sub graphs. If our graph has a concept of time our life is easy — we can split the graph at a point in time and the training set will be from before the time, the test set after.\n",
    "\n",
    "This is still not a perfect solution and we’ll need to try and ensure that the general network structure in the training and test sub graphs is similar.\n",
    "\n",
    "Once we’ve done that we’ll have pairs of nodes in our train and test set that have relationships between them. They will be the __positive examples__ in our machine learning model.\n",
    "\n",
    "We are lucky that our citation graph contains a times. We can create train and test graphs by splitting the data on a particular year. Now we need to figure out what year that should be. Let's have a look at the distribution of the first year that co-authors collaborated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "MATCH p=()-[r:CO_AUTHOR]->() \n",
    "WITH r.year AS year, count(*) AS count\n",
    "ORDER BY year\n",
    "RETURN toString(year) AS year, count\n",
    "\"\"\"\n",
    "by_year = graph.run(query).to_data_frame()\n",
    "\n",
    "ax = by_year.plot(kind='bar', x='year', y='count', legend=None, figsize=(15,8))\n",
    "ax.xaxis.set_label_text(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 2006 would act as a good year on which to split the data. We'll take all the co-authorships from 2005 and earlier as our train graph, and everything from 2006 onwards as the test graph.\n",
    "\n",
    "Let's create explicit `CO_AUTHOR_EARLY` and `CO_AUTHOR_LATE` relationships in our graph based on that year. The following code will create these relationships for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constraints_added: 0\n",
       "constraints_removed: 0\n",
       "contains_updates: False\n",
       "indexes_added: 0\n",
       "indexes_removed: 0\n",
       "labels_added: 0\n",
       "labels_removed: 0\n",
       "nodes_created: 0\n",
       "nodes_deleted: 0\n",
       "properties_set: 0\n",
       "relationships_created: 0\n",
       "relationships_deleted: 0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "MATCH (a)-[r:CO_AUTHOR]->(b) \n",
    "where r.year < 2006\n",
    "MERGE (a)-[:CO_AUTHOR_EARLY {year: r.year}]-(b);\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query).stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constraints_added: 0\n",
       "constraints_removed: 0\n",
       "contains_updates: True\n",
       "indexes_added: 0\n",
       "indexes_removed: 0\n",
       "labels_added: 0\n",
       "labels_removed: 0\n",
       "nodes_created: 0\n",
       "nodes_deleted: 0\n",
       "properties_set: 74128\n",
       "relationships_created: 74128\n",
       "relationships_deleted: 0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "MATCH (a)-[r:CO_AUTHOR]->(b) \n",
    "where r.year >= 2006\n",
    "MERGE (a)-[:CO_AUTHOR_LATE {year: r.year}]-(b);\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query).stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly check how many co-author relationship we have in each of these sub graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0  81096"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "MATCH ()-[:CO_AUTHOR_EARLY]->()\n",
    "RETURN count(*) AS count\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0  74128"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "MATCH ()-[:CO_AUTHOR_LATE]->()\n",
    "RETURN count(*) AS count\n",
    "\"\"\"\n",
    "\n",
    "graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a split of 52-48, which is a bit on the high side, but should be ok. Now for the __negative examples__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative examples\n",
    "\n",
    "The simplest approach would be to use all pair of nodes that don’t have a relationship. __The problem with this approach is that there are significantly more examples of pairs of nodes that don’t have a relationship than there are pairs of nodes that do__.\n",
    "\n",
    "The maximum number of negative examples is equal to:\n",
    "\n",
    "```\n",
    "# negative examples = (# nodes)² - (# relationships) - (# nodes)\n",
    "```\n",
    "\n",
    "i.e. the number of nodes squared, minus the relationships that the graph has, minus self relationships.\n",
    "\n",
    "If we use all of these negative examples in our training set we will have a massive class imbalance — there are many negative examples and relatively few positive ones.\n",
    "\n",
    "A model trained using data that’s this imbalanced will achieve very high accuracy by __predicting that any pair of nodes don’t have a relationship__ between them, which is not quite what we want!\n",
    "\n",
    "So we need to try and reduce the number of negative examples. An approach described in several link prediction papers is to use pairs of nodes that are a __specific number of hops away from each other__.\n",
    "\n",
    "This will significantly reduce the number of negative examples, although there will still be a lot more negative examples than positive.\n",
    "\n",
    "To solve this problem we either need to down sample the negative examples or up sample the positive examples.\n",
    "\n",
    "We're going to take the down sampling approach in this guide, and the following function will do this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(df):\n",
    "    copy = df.copy()\n",
    "    zero = Counter(copy.label.values)[0]\n",
    "    un = Counter(copy.label.values)[1]\n",
    "    n = zero - un\n",
    "    copy = copy.drop(copy[copy.label == 0].sample(n=n, random_state=1).index)\n",
    "    return copy.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to build our train and test datasets based on the train and test sub graphs that we created. \n",
    "\n",
    "* The positive examples will be taken directly from the graph. \n",
    "* Our negative examples will be found by looking for people who are 2 or 3 hops away from each other, excluding those that have already collaborated. We'll then down sample those examples to equal the size of the positive examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_existing_links = graph.run(\"\"\"\n",
    "MATCH (author:Author)-[:CO_AUTHOR_EARLY]->(other:Author)\n",
    "RETURN id(author) AS node1, id(other) AS node2, 1 AS label\n",
    "\"\"\").to_data_frame()\n",
    "\n",
    "train_missing_links = graph.run(\"\"\"\n",
    "MATCH (author:Author)\n",
    "WHERE (author)-[:CO_AUTHOR_EARLY]-()\n",
    "MATCH (author)-[:CO_AUTHOR_EARLY*2..3]-(other)\n",
    "WHERE not((author)-[:CO_AUTHOR_EARLY]-(other))\n",
    "RETURN id(author) AS node1, id(other) AS node2, 0 AS label\n",
    "\"\"\").to_data_frame()\n",
    "train_missing_links = train_missing_links.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = train_missing_links.append(train_existing_links, ignore_index=True)\n",
    "training_df['label'] = training_df['label'].astype('category')\n",
    "training_df = down_sample(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look what our train DataFrame contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144026</th>\n",
       "      <td>0</td>\n",
       "      <td>19830</td>\n",
       "      <td>10608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119405</th>\n",
       "      <td>0</td>\n",
       "      <td>18877</td>\n",
       "      <td>170852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006849</th>\n",
       "      <td>1</td>\n",
       "      <td>72365</td>\n",
       "      <td>72363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042189</th>\n",
       "      <td>1</td>\n",
       "      <td>214365</td>\n",
       "      <td>213561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042056</th>\n",
       "      <td>1</td>\n",
       "      <td>45129</td>\n",
       "      <td>210220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label   node1   node2\n",
       "144026      0   19830   10608\n",
       "119405      0   18877  170852\n",
       "1006849     1   72365   72363\n",
       "1042189     1  214365  213561\n",
       "1042056     1   45129  210220"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the process for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_existing_links = graph.run(\"\"\"\n",
    "MATCH (author:Author)-[:CO_AUTHOR_LATE]->(other:Author)\n",
    "RETURN id(author) AS node1, id(other) AS node2, 1 AS label\n",
    "\"\"\").to_data_frame()\n",
    "\n",
    "test_missing_links = graph.run(\"\"\"\n",
    "MATCH (author:Author)\n",
    "WHERE (author)-[:CO_AUTHOR_LATE]-()\n",
    "MATCH (author)-[:CO_AUTHOR_LATE*2..3]-(other)\n",
    "WHERE not((author)-[:CO_AUTHOR_LATE]-(other))\n",
    "RETURN id(author) AS node1, id(other) AS node2, 0 AS label\n",
    "\"\"\").to_data_frame()\n",
    "test_missing_links = test_missing_links.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_missing_links.append(test_existing_links, ignore_index=True)\n",
    "test_df['label'] = test_df['label'].astype('category')\n",
    "test_df = down_sample(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it's time to sample our test DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100491</th>\n",
       "      <td>0</td>\n",
       "      <td>19808</td>\n",
       "      <td>19808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970657</th>\n",
       "      <td>0</td>\n",
       "      <td>205177</td>\n",
       "      <td>210207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694138</th>\n",
       "      <td>0</td>\n",
       "      <td>166115</td>\n",
       "      <td>227410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330910</th>\n",
       "      <td>1</td>\n",
       "      <td>249099</td>\n",
       "      <td>249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799291</th>\n",
       "      <td>0</td>\n",
       "      <td>179975</td>\n",
       "      <td>227669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label   node1   node2\n",
       "100491      0   19808   19808\n",
       "970657      0  205177  210207\n",
       "694138      0  166115  227410\n",
       "1330910     1  249099  249100\n",
       "799291      0  179975  227669"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing a machine learning algorithm\n",
    "\n",
    "We’ll create our machine learning pipeline based on a random forest classifier. This method is well suited as our data set will be comprised of a mix of strong and weak features. While the weak features will sometimes be helpful, the random forest method will ensure we don’t create a model that only fits our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=30, max_depth=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating graphy features\n",
    "\n",
    "We’ll start by creating a simple model that tries to predict whether two authors will have a future collaboration based on features extracted from common authors, preferential attachment, and the total union of neighbors.\n",
    "\n",
    "The following function computes each of these measures for pairs of nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_graphy_features(data, rel_type):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "           pair.node2 AS node2,\n",
    "           algo.linkprediction.commonNeighbors(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS cn,\n",
    "           algo.linkprediction.preferentialAttachment(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS pa,\n",
    "           algo.linkprediction.totalNeighbors(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS tn\n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]\n",
    "    features = graph.run(query, {\"pairs\": pairs, \"relType\": rel_type}).to_data_frame()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the function to our training DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'node1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-d88573fcacdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_graphy_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CO_AUTHOR_EARLY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-a92a73de91f3>\u001b[0m in \u001b[0;36mapply_graphy_features\u001b[0;34m(data, rel_type)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"node1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"node2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode2\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mnode1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"node1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"node2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"pairs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relType\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrel_type\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"node1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"node2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/data-science-training/a/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     45\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/data-science-training/a/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    527\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    528\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/data-science-training/a/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                             right_keys.append(\n\u001b[0;32m--> 833\u001b[0;31m                                 right._get_label_or_level_values(rk))\n\u001b[0m\u001b[1;32m    834\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/data-science-training/a/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1705\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1707\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'node1'"
     ]
    }
   ],
   "source": [
    "training_df = apply_graphy_features(training_df, \"CO_AUTHOR_EARLY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is what our DataFrame looks like now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>cn</th>\n",
       "      <th>pa</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>112840</td>\n",
       "      <td>27596</td>\n",
       "      <td>1.000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>170094</td>\n",
       "      <td>170095</td>\n",
       "      <td>2.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>117252</td>\n",
       "      <td>129963</td>\n",
       "      <td>1.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10705</td>\n",
       "      <td>179812</td>\n",
       "      <td>0.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>26.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>123659</td>\n",
       "      <td>214303</td>\n",
       "      <td>3.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label   node1   node2    cn      pa     tn\n",
       "0     0  112840   27596 1.000  42.000 12.000\n",
       "1     1  170094  170095 2.000   9.000  4.000\n",
       "2     0  117252  129963 1.000  54.000 20.000\n",
       "3     0   10705  179812 0.000 105.000 26.000\n",
       "4     1  123659  214303 3.000  32.000  9.000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same to our test DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = apply_graphy_features(test_df, \"CO_AUTHOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "      <th>cn</th>\n",
       "      <th>pa</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19808</td>\n",
       "      <td>19808</td>\n",
       "      <td>0.000</td>\n",
       "      <td>361.000</td>\n",
       "      <td>19.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>205177</td>\n",
       "      <td>210207</td>\n",
       "      <td>2.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>166115</td>\n",
       "      <td>227410</td>\n",
       "      <td>0.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>249099</td>\n",
       "      <td>249100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>179975</td>\n",
       "      <td>227669</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>9.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label   node1   node2    cn      pa     tn\n",
       "0     0   19808   19808 0.000 361.000 19.000\n",
       "1     0  205177  210207 2.000  56.000 13.000\n",
       "2     0  166115  227410 0.000  32.000 12.000\n",
       "3     1  249099  249100 0.000   3.000  4.000\n",
       "4     0  179975  227669 0.000  18.000  9.000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a model based on these graphy features. We'll start by just using one of the features - common neighbors. \n",
    "\n",
    "The following code builds a random forest model, evaluates it against the test dataset, and then indicates which of the features had the most importance in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"cn\"]\n",
    "\n",
    "X = training_df[columns]\n",
    "y = training_df[\"label\"]\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to evalute our model. We're going to compute its accuracy, precision, and recall. After we've done that we'll return the importance of each feature used in our model. The following functions will help with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, actual):\n",
    "    display(\"Accuracy\", accuracy_score(actual, predictions))\n",
    "    display(\"Precision\", precision_score(actual, predictions))\n",
    "    display(\"Recall\", recall_score(actual, predictions))\n",
    "\n",
    "def feature_importance(columns, classifier):        \n",
    "    display(\"Feature Importance\")\n",
    "    for feature, score in sorted(list(zip(columns, classifier.feature_importances_)), key = lambda x: x[1]*-1):\n",
    "        print(feature, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8541306928556012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Precision'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.943608895498175"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Recall'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7532781135333477"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Feature Importance'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn 1.0\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(test_df[columns])\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "evaluate_model(predictions, y_test)\n",
    "feature_importance(columns, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores for accuracy and precision aren't bad, but our recall isn't very good. Let's see what happens if we include preferential attachment and total neighbors as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9180404165767322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Precision'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9204395902584628"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Recall'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9151872436865962"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Feature Importance'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn 0.7103957194252104\n",
      "pa 0.1694740257663287\n",
      "tn 0.12013025480846093\n"
     ]
    }
   ],
   "source": [
    "columns = [\"cn\", \"pa\", \"tn\"]\n",
    "\n",
    "X = training_df[columns]\n",
    "y = training_df[\"label\"]\n",
    "classifier.fit(X, y)\n",
    "\n",
    "predictions = classifier.predict(test_df[columns])\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "evaluate_model(predictions, y_test)\n",
    "feature_importance(columns, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Neighbors is the dominant feature, but including the two other features has improved the accuracy and recall of our model.\n",
    "\n",
    "Now we're going to add some new features that are generated from graph algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangles and The Clustering Coefficient\n",
    "\n",
    "We'll start by running the [triangle count](https://neo4j.com/docs/graph-algorithms/current/algorithms/triangle-counting-clustering-coefficient/) algorithm over our test and train sub graphs. This algorithm will return the number of triangles that each node forms, as well as each node's clustering coefficient. The clustering coefficient of a node indicates the likelihood that its neighbours are also connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averageClusteringCoefficient</th>\n",
       "      <th>clusteringCoefficientProperty</th>\n",
       "      <th>computeMillis</th>\n",
       "      <th>loadMillis</th>\n",
       "      <th>nodeCount</th>\n",
       "      <th>p1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p100</th>\n",
       "      <th>p25</th>\n",
       "      <th>p5</th>\n",
       "      <th>p50</th>\n",
       "      <th>p75</th>\n",
       "      <th>p90</th>\n",
       "      <th>p95</th>\n",
       "      <th>p99</th>\n",
       "      <th>postProcessingMillis</th>\n",
       "      <th>triangleCount</th>\n",
       "      <th>write</th>\n",
       "      <th>writeMillis</th>\n",
       "      <th>writeProperty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.375</td>\n",
       "      <td>coefficientTrain</td>\n",
       "      <td>114</td>\n",
       "      <td>532</td>\n",
       "      <td>80299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>2013</td>\n",
       "      <td>97205</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>trianglesTrain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   averageClusteringCoefficient clusteringCoefficientProperty  computeMillis  \\\n",
       "0                         0.375              coefficientTrain            114   \n",
       "\n",
       "   loadMillis  nodeCount  p1  p10  p100  p25  p5  p50  p75  p90  p95  p99  \\\n",
       "0         532      80299   0    0   787    0   0    0    3    7   15   45   \n",
       "\n",
       "   postProcessingMillis  triangleCount  write  writeMillis   writeProperty  \n",
       "0                  2013          97205   True            9  trianglesTrain  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run(\"\"\"\n",
    "CALL algo.triangleCount('Author', 'CO_AUTHOR_EARLY', { write:true,\n",
    "writeProperty:'trianglesTrain', clusteringCoefficientProperty:'coefficientTrain'});\n",
    "\"\"\").to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averageClusteringCoefficient</th>\n",
       "      <th>clusteringCoefficientProperty</th>\n",
       "      <th>computeMillis</th>\n",
       "      <th>loadMillis</th>\n",
       "      <th>nodeCount</th>\n",
       "      <th>p1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p100</th>\n",
       "      <th>p25</th>\n",
       "      <th>p5</th>\n",
       "      <th>p50</th>\n",
       "      <th>p75</th>\n",
       "      <th>p90</th>\n",
       "      <th>p95</th>\n",
       "      <th>p99</th>\n",
       "      <th>postProcessingMillis</th>\n",
       "      <th>triangleCount</th>\n",
       "      <th>write</th>\n",
       "      <th>writeMillis</th>\n",
       "      <th>writeProperty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.657</td>\n",
       "      <td>coefficientTest</td>\n",
       "      <td>77</td>\n",
       "      <td>182</td>\n",
       "      <td>80299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>91</td>\n",
       "      <td>918</td>\n",
       "      <td>199813</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>trianglesTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   averageClusteringCoefficient clusteringCoefficientProperty  computeMillis  \\\n",
       "0                         0.657               coefficientTest             77   \n",
       "\n",
       "   loadMillis  nodeCount  p1  p10  p100  p25  p5  p50  p75  p90  p95  p99  \\\n",
       "0         182      80299   0    0   787    1   0    3    6   15   26   91   \n",
       "\n",
       "   postProcessingMillis  triangleCount  write  writeMillis  writeProperty  \n",
       "0                   918         199813   True            3  trianglesTest  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run(\"\"\"\n",
    "CALL algo.triangleCount('Author', 'CO_AUTHOR', { write:true,\n",
    "writeProperty:'trianglesTest', clusteringCoefficientProperty:'coefficientTest'});\n",
    "\"\"\").to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will add these features to our train and test DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_triangles_features(data, triangles_prop, coefficient_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    apoc.coll.min([p1[$trianglesProp], p2[$trianglesProp]]) AS minTriangles,\n",
    "    apoc.coll.max([p1[$trianglesProp], p2[$trianglesProp]]) AS maxTriangles,\n",
    "    apoc.coll.min([p1[$coefficientProp], p2[$coefficientProp]]) AS minCoefficient,\n",
    "    apoc.coll.max([p1[$coefficientProp], p2[$coefficientProp]]) AS maxCoefficient\n",
    "    \"\"\"    \n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]    \n",
    "    params = {\n",
    "    \"pairs\": pairs,\n",
    "    \"trianglesProp\": triangles_prop,\n",
    "    \"coefficientProp\": coefficient_prop\n",
    "    }\n",
    "    features = graph.run(query, params).to_data_frame()    \n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = apply_triangles_features(training_df, \"trianglesTrain\", \"coefficientTrain\")\n",
    "test_df = apply_triangles_features(test_df, \"trianglesTest\", \"coefficientTest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's train and evaluate a model with these features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9508822577163825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Precision'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9513206222318246"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Recall'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9503966112669976"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Feature Importance'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn 0.6032326473539613\n",
      "minTriangles 0.0923510285998431\n",
      "maxTriangles 0.08860834393172944\n",
      "tn 0.06918356458361527\n",
      "minCoefficient 0.05559968258755945\n",
      "pa 0.05079562974137744\n",
      "maxCoefficient 0.04022910320191402\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    \"cn\", \"pa\", \"tn\", # graph features\n",
    "    \"minTriangles\", \"maxTriangles\", \"minCoefficient\", \"maxCoefficient\" # triangle features  \n",
    "]\n",
    "\n",
    "X = training_df[columns]\n",
    "y = training_df[\"label\"]\n",
    "classifier.fit(X, y)\n",
    "\n",
    "predictions = classifier.predict(test_df[columns])\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "evaluate_model(predictions, y_test)\n",
    "feature_importance(columns, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient features haven't added much to our model, but the triangles are useful. Next we're going to see if community detection algorithms can help improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Detection\n",
    "\n",
    "Community detection algorithms evaluate how a group is clustered or partitioned. Nodes are considered more similar to nodes that fall in their community than to nodes in other communities.\n",
    "\n",
    "We'll run two community detection algorithms over the train and test sub graphs - Label Propagation and Louvain. First up, Label Propagation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityCount</th>\n",
       "      <th>computeMillis</th>\n",
       "      <th>didConverge</th>\n",
       "      <th>iterations</th>\n",
       "      <th>loadMillis</th>\n",
       "      <th>nodes</th>\n",
       "      <th>p1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p100</th>\n",
       "      <th>p25</th>\n",
       "      <th>...</th>\n",
       "      <th>p75</th>\n",
       "      <th>p90</th>\n",
       "      <th>p95</th>\n",
       "      <th>p99</th>\n",
       "      <th>partitionProperty</th>\n",
       "      <th>postProcessingMillis</th>\n",
       "      <th>weightProperty</th>\n",
       "      <th>write</th>\n",
       "      <th>writeMillis</th>\n",
       "      <th>writeProperty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47257</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>80299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>partitionTrain</td>\n",
       "      <td>404</td>\n",
       "      <td>weight</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>partitionTrain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   communityCount  computeMillis  didConverge  iterations  loadMillis  nodes  \\\n",
       "0           47257             60        False           1          85  80299   \n",
       "\n",
       "   p1  p10  p100  p25  ...  p75  p90  p95  p99  partitionProperty  \\\n",
       "0   1    1    63    1  ...    1    3    5   10     partitionTrain   \n",
       "\n",
       "   postProcessingMillis weightProperty  write writeMillis   writeProperty  \n",
       "0                   404         weight   True          14  partitionTrain  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run(\"\"\"\n",
    "CALL algo.labelPropagation(\"Author\", \"CO_AUTHOR_EARLY\", \"BOTH\",\n",
    "{partitionProperty: \"partitionTrain\"});\n",
    "\"\"\").to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityCount</th>\n",
       "      <th>computeMillis</th>\n",
       "      <th>didConverge</th>\n",
       "      <th>iterations</th>\n",
       "      <th>loadMillis</th>\n",
       "      <th>nodes</th>\n",
       "      <th>p1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p100</th>\n",
       "      <th>p25</th>\n",
       "      <th>...</th>\n",
       "      <th>p75</th>\n",
       "      <th>p90</th>\n",
       "      <th>p95</th>\n",
       "      <th>p99</th>\n",
       "      <th>partitionProperty</th>\n",
       "      <th>postProcessingMillis</th>\n",
       "      <th>weightProperty</th>\n",
       "      <th>write</th>\n",
       "      <th>writeMillis</th>\n",
       "      <th>writeProperty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21561</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>80299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>partitionTest</td>\n",
       "      <td>314</td>\n",
       "      <td>weight</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>partitionTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   communityCount  computeMillis  didConverge  iterations  loadMillis  nodes  \\\n",
       "0           21561              9        False           1         107  80299   \n",
       "\n",
       "   p1  p10  p100  p25  ...  p75  p90  p95  p99  partitionProperty  \\\n",
       "0   1    1   221    1  ...    4    7   10   22      partitionTest   \n",
       "\n",
       "   postProcessingMillis weightProperty  write writeMillis  writeProperty  \n",
       "0                   314         weight   True           5  partitionTest  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run(\"\"\"\n",
    "CALL algo.labelPropagation(\"Author\", \"CO_AUTHOR\", \"BOTH\",\n",
    "{partitionProperty: \"partitionTest\"});\n",
    "\"\"\").to_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now Louvain. The Louvain algorithm returns intermediate communities, which are useful for finding fine grained communities that exist in a graph. We'll add a property to each node containing the community revealed on the first iteration of the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constraints_added: 0\n",
       "constraints_removed: 0\n",
       "contains_updates: True\n",
       "indexes_added: 0\n",
       "indexes_removed: 0\n",
       "labels_added: 0\n",
       "labels_removed: 0\n",
       "nodes_created: 0\n",
       "nodes_deleted: 0\n",
       "properties_set: 80299\n",
       "relationships_created: 0\n",
       "relationships_deleted: 0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run(\"\"\"\n",
    "CALL algo.louvain.stream(\"Author\", \"CO_AUTHOR_EARLY\", {includeIntermediateCommunities:true})\n",
    "YIELD nodeId, community, communities\n",
    "WITH algo.getNodeById(nodeId) AS node, communities[0] AS smallestCommunity\n",
    "SET node.louvainTrain = smallestCommunity;\n",
    "\"\"\").stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constraints_added: 0\n",
       "constraints_removed: 0\n",
       "contains_updates: True\n",
       "indexes_added: 0\n",
       "indexes_removed: 0\n",
       "labels_added: 0\n",
       "labels_removed: 0\n",
       "nodes_created: 0\n",
       "nodes_deleted: 0\n",
       "properties_set: 80299\n",
       "relationships_created: 0\n",
       "relationships_deleted: 0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.run(\"\"\"\n",
    "CALL algo.louvain.stream(\"Author\", \"CO_AUTHOR\", {includeIntermediateCommunities:true})\n",
    "YIELD nodeId, community, communities\n",
    "WITH algo.getNodeById(nodeId) AS node, communities[0] AS smallestCommunity\n",
    "SET node.louvainTest = smallestCommunity;\n",
    "\"\"\").stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will add these features to our train and test DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_community_features(data, partition_prop, louvain_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1) WHERE id(p1) = pair.node1\n",
    "    MATCH (p2) WHERE id(p2) = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    algo.linkprediction.sameCommunity(p1, p2, $partitionProp) AS sp,    \n",
    "    algo.linkprediction.sameCommunity(p1, p2, $louvainProp) AS sl\n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]\n",
    "    params = {\n",
    "    \"pairs\": pairs,\n",
    "    \"partitionProp\": partition_prop,\n",
    "    \"louvainProp\": louvain_prop\n",
    "    }\n",
    "    features = graph.run(query, params).to_data_frame()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = apply_community_features(training_df, \"partitionTrain\", \"louvainTrain\")\n",
    "test_df = apply_community_features(test_df, \"partitionTest\", \"louvainTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9625175372328945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Precision'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9639507977103885"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Recall'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9609729117202677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Feature Importance'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn 0.34072273226828903\n",
      "sl 0.2914461230290112\n",
      "sp 0.14287965611656409\n",
      "minTriangles 0.06688729655437162\n",
      "minCoefficient 0.047021079786739355\n",
      "maxTriangles 0.035705467530987245\n",
      "tn 0.02996987214488078\n",
      "maxCoefficient 0.02418406680930397\n",
      "pa 0.021183705759852695\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    \"cn\", \"pa\", \"tn\", # graph features\n",
    "    \"minTriangles\", \"maxTriangles\", \"minCoefficient\", \"maxCoefficient\", # triangle features  \n",
    "    \"sp\", \"sl\" # community features\n",
    "]\n",
    "\n",
    "X = training_df[columns]\n",
    "y = training_df[\"label\"]\n",
    "classifier.fit(X, y)\n",
    "\n",
    "predictions = classifier.predict(test_df[columns])\n",
    "y_test = test_df[\"label\"]\n",
    "\n",
    "evaluate_model(predictions, y_test)\n",
    "feature_importance(columns, classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
